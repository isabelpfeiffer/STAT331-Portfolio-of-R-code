---
title: "STAT 331 Portfolio"
author: "Isabel Pfeiffer"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

I have met the requirements by submitting revisions most of the time, always being patient and respectful when collaborating, making an effort to push myself, especially towards the second half of the quarter, and providing kind, constructive feedback on peer reviews.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r}
#| label: wd-1-csv

From Lab 2, Question 1:
  
  library(here)
surveys <- read_csv(here("data", "surveys.csv"))
```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

From PA4 Question1:
  
military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip  = 7, 
                      n_max = 191)
```

-   `txt`

```{r}
#| label: wd-1-txt

From Check in 2.3:

  ages_mystery <- read_delim(
    file = here::here("Week 2", "Check-ins", "Ages_Data", "ages_mystery.txt"), 
    delim = "|")

```

**WD-2: I can select necessary columns from a data set.**

```{r}
#| label: wd-2

From Lab 3 Question 5:
  
teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  select(course_id,
         teacher_id,
         question_no,
         no_participants,
         resp_share,
         SET_score_avg,
         percent_failed_cur,
         academic_degree,
         seniority,
         sex) |>
  mutate(teacher_id = as.character(teacher_id),
         course_id = as.character(course_id)) |>
  filter(no_participants >= 10)
```

**WD-3: I can filter rows from a data frame for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r}
#| label: wd-3-numeric

From Lab 3 Question 5:
  
teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  select(course_id,
         teacher_id,
         question_no,
         no_participants,
         resp_share,
         SET_score_avg,
         percent_failed_cur,
         academic_degree,
         seniority,
         sex) |>
  mutate(teacher_id = as.character(teacher_id),
         course_id = as.character(course_id)) |>
  filter(no_participants >= 10)
```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-3-string

From Lab 3 Question 12:
  
female_instructors <- teacher_evals_clean |>
  filter(str_detect(sex, "female"), 
         str_detect(academic_degree, "dr|prof")) |>
  group_by(teacher_id) |>
  summarize(avg_resp_share = mean(resp_share, na.rm = TRUE), .groups = 'drop') |>
  mutate(
    max_resp = max(avg_resp_share, na.rm = TRUE),
    min_resp = min(avg_resp_share, na.rm = TRUE)) |>
  filter(avg_resp_share == max_resp | avg_resp_share == min_resp) |>
  select(teacher_id, avg_resp_share)

female_instructors

```

**Revision: I modified my first filter to include a function from the stringr package. I used str_detect to check if the column "sex" had the string "female" and if the column "academic_degree" had either "dr" or "prof". To put them both in the same line I used the \| operator which acts as or.**

-   factor

```{r}
#| label: wd-3-factor

From Lab 8 Question 3:
  
evals |>
  distinct(teacher_id, .keep_all = TRUE) |>
  mutate(
    seniority = as.numeric(seniority),
    sen_level = ifelse(seniority <= 4,
                       "Junior (4 years or less)",
                       "Senior (more than 4 years)")) |>
  pivot_longer(cols = c(sex, 
                        sen_level, 
                        academic_degree),
               names_to = "demographic",
               values_to = "category") |>
  count(category) |>
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = list(n = 0)) |>
  select(Female = female,
         Male = male,
         "Junior (4 years or less)",
         "Senior (more than 4 years)",
         `No Degree` = no_dgr,
         Masters = ma,
         Doctorate = dr,
         Professor = prof) |>
  kable(format = "html", 
        caption = "Demographic Summary of Teachers from Evals Dataset") |>
  kable_styling()
```

**Comment: While the original variable types in Lab 3 Question 7 were not factors, in Lab 8 on Question 2, we used map_at to convert the variables from Lab 3 Question 7 to factors. So the variable types in this code chunk include factors.**

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date
From Lab 3 Question 3:
  
teacher_evals <- teacher_evals |>
  mutate(class_duration_days = ddays(class_duration)) |>  
  filter(class_duration_days == min(class_duration_days, na.rm = TRUE),  
         class_duration_days == max(class_duration_days, na.rm = TRUE))

```

**Revision: To show use of a lubridate package function, I used the ddays fucntion to convert the class_duration to days, and then included a filter to output the minimum and maximum class duration in days.**

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

```{r}
#| label: wd-4-numeric

FRom Lab 9 Question 3:
  
results_updated2 <- enframe(results_updated, name = "simulation number", value = "ncorrect") |>
  count(ncorrect) |>
  complete(ncorrect = 0:4, fill = list(n = 0)) |>
  mutate(Proportion = n / sum(n))

bar <- 
  ggplot(results_updated2, aes(x = factor(ncorrect), y = Proportion)) +
  geom_bar(stat = "identity", fill = "red") +
  labs(
    title = "Proportion of Simulations of Babies Given to Correct Parent(s)",
    x = "Number of Correct Matches of Babies to Parent(s)",
    y = ""
  ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0,1)) +
  theme_minimal()
                 
#https://tidyr.tidyverse.org/reference/complete.html 
bar

```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

From Lab 7 Question 1:
  fish_data |>
  summarise(across(.fns = ~sum(is.na(.)), .names = "missing_{.col}")) |>
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "missing_count") |>
  mutate(variable = str_to_title(variable)) 
```

**Revision: I added the str_to_title function to show use from stringr package. I chose to use this function because it capitalized the first letter of my variable in my output.**

-   factor (example must use functions from **forcats**)

```{r}
#| label: wd-4-factor

From Lab 7 Question 7:

fish_long <- fish_data |> 
  mutate(length_scaled = rescale_01(length)) |>
  pivot_longer(cols = c(length, length_scaled),
               names_to = "Length_Type",
               values_to = "Length_Value") |>
  mutate(Length_Type = fct_recode(Length_Type,
                                  "Original Length" = "length",
                                  "Rescaled Length" = "length_scaled"))
```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

From Lab 3 Question 3:
  
teacher_evals <- teacher_evals |>
  mutate(class_duration_days = ddays(class_duration)) |>
  summarise(average_days = mean(class_duration_days, na.rm = TRUE))


```

**Revision: To show I can use a function from the lubridate package, I created and stored a new variable inside of the teacher_evals data set that consists of the average duration of the class in days.**

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r}
#| label: wd-5-left

From Lab 9 Question 2:
  
results_updated <- map_int(1:10000, ~randomBabies(4))


results_df <- enframe(results_updated, name = "simulation_number", value = "ncorrect") |>
  count(ncorrect)

labels <- tibble(
  ncorrect = 0:4,  
  description = c("No matches", "One match", "Two matches", "Three matches", "Four matches"))



missing_scenarios <- tibble(ncorrect = 0:4) |> 
  anti_join(results_df, by = "ncorrect")
complete_results <- bind_rows(
  results_df,
  missing_scenarios |> 
    mutate(n = 0))


complete_results_with_labels <- complete_results |>
  left_join(labels, by = "ncorrect") |> 
  mutate(Proportion = n / sum(n)) 


result_table <- complete_results_with_labels |>
  select(description, Proportion) |> 
  pivot_wider(
    names_from = description,
    values_from = Proportion,
    values_fill = list(Proportion = 0)) |>
  gt() |>
  tab_header(
    title = "Percentage of Simulations that had Correct Matches of Baby to Parents",
    subtitle = "10,000 Simulations of 4 Babies") |>
  fmt_percent(
    columns = everything(),
    decimals = 2)


result_table

```

**Revision: To showcase the use of joins I revised a few parts of my original code. I ran the simulations with 4 babies. I stored that inside of results_df. I used an anti_join to check if any of the scenarios would be missing from the results, and to ensure that even if some proportions were equivalent to 0 they were still shown in the table. I used bind_rows to put the missing scenarios inside the results data frame. After creating the labels I wanted in the table, I used a left_join to merge these labels with the results. The rest of the code was from my original code for this question in Lab 9, with the additional reference of https://sparkbyexamples.com/r-programming/r-anti-join.**

-   `right_join()`

```{r}
#| label: wd-5-right
From Lab 3 Question 9:
  
questions_reference <- data.frame(question_no = 901:909)

teacher_evals_clean |>
  right_join(questions_reference, by = "question_no") |>
  group_by(course_id, teacher_id) |>
  summarize(question_count = n_distinct(question_no, na.rm = TRUE), .groups = 'drop') |>
  filter(question_count == 9)
```

**Revision: To showcase a use of right_join, I modified the original code. I created a seperate data frame for the 9 questions, and then used a right_join to make sure that teacher-course group is checked for the 9 questions being asked. Running this code got me the same output as my original code, but just incorporates a right_join. I also referenced https://stackoverflow.com/questions/70536460/why-do-results-differ-for-dplyr-left-join-and-right-join-using-these-two-dat and https://ouzhang.me/blog/nine-join/.**

-   `inner_join()`

```{r}
#| label: wd-5-inner
From Lab 9 Question 2:
  
library(gt)

results_updated <- map_int(1:10000, ~randomBabies(4))

results_df <- enframe(results_updated, name = "simulation_number", value = "ncorrect") |>
  count(ncorrect)

labels <- tibble(
  ncorrect = 0:4,  
  description = c("No matches", "One match", "Two matches", "Three matches", "Four matches"))

missing_scenarios <- tibble(ncorrect = 0:4) |> 
  anti_join(results_df, by = "ncorrect")

complete_results <- bind_rows(
  results_df,
  missing_scenarios |> 
    mutate(n = 0))

complete_results_with_labels <- complete_results |>
  inner_join(labels, by = "ncorrect") |>  
  mutate(Proportion = n / sum(n))  

result_table <- complete_results_with_labels |>
  select(description, Proportion) |> 
  pivot_wider(
    names_from = description,
    values_from = Proportion,
    values_fill = list(Proportion = 0)) |>
  gt() |>
  tab_header(
    title = "Percentage of Simulations that had Correct Matches of Baby to Parents",
    subtitle = "10,000 Simulations of 4 Babies") |>
  fmt_percent(
    columns = everything(),
    decimals = 2)

result_table


```

**Revision: To showcase the use of joins I revised a few parts of my original code. I ran the simulations with 4 babies. I stored that inside of results_df. I used an anti_join to check if any of the scenarios would be missing from the results, and to ensure that even if some proportions were equivalent to 0 they were still shown in the table. I used bind_rows to put the missing scenarios inside the results data frame. After creating the labels I wanted in the table, I used an inner_join to join these labels with complete_results, including only the rows that in both the complete_results and labels data frames. The rest of the code was from my original code for this question in Lab 9, with the additional reference of https://r4ds.hadley.nz/joins.**

-   `full_join()`

```{r}
#| label: wd-5-full
*removed from Final Portfolio*
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

From Lab 7 Question 2:
  
missing_data <- fish_data |> 
  filter(is.na(weight)) |> 
  select(year, section, trip) |> 
  distinct()


filtered_data <- fish_data |> 
  semi_join(missing_data, by = c("year", "section", "trip")) |> 
  group_by(year, section, trip) |> 
  summarise(missing = n(), .groups = "drop") |> 
  ggplot(aes(x = missing, 
             y = interaction(year, trip), 
             fill = section)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_manual(values = c("gray80", "darkred")) +
  labs(title = "Frequency of Missing Weight Values by Year and Trip",
       subtitle = "Year and trip number",
       x = "Count of Missing Values of Weight",
       y = "",
       fill = "Section") +
  theme_minimal() +
  theme(
    aspect.ratio = 1/2, 
    axis.text.y = element_text(size = 8, angle = 0, hjust = 1), 
    legend.title = element_text(size = 10),
    legend.position = "bottom", 
    legend.direction = "horizontal")
filtered_data
```

**Revision: To include the use of a semi_join, I revised the initial code. I created a new data frame with the missing values data and then used the semi_join to filter the fish_data data frame. This made it to only output into the plot the rows matching with the missing_data data frame that was created. I also revised the code so that on the graph output the labels were not rotated so that people would not have to tilt their heads. Additional reference of https://r4ds.hadley.nz/joins.**

-   `anti_join()`

```{r}
#| label: wd-6-anti

From Lab 9 Question 2:
  
results_updated <- map_int(1:10000, ~randomBabies(4))


results_df <- enframe(results_updated, name = "simulation_number", value = "ncorrect") |>
  count(ncorrect)

labels <- tibble(
  ncorrect = 0:4,  
  description = c("No matches", "One match", "Two matches", "Three matches", "Four matches"))



missing_scenarios <- tibble(ncorrect = 0:4) |> 
  anti_join(results_df, by = "ncorrect")
complete_results <- bind_rows(
  results_df,
  missing_scenarios |> 
    mutate(n = 0))


complete_results_with_labels <- complete_results |>
  left_join(labels, by = "ncorrect") |> 
  mutate(Proportion = n / sum(n)) 


result_table <- complete_results_with_labels |>
  select(description, Proportion) |> 
  pivot_wider(
    names_from = description,
    values_from = Proportion,
    values_fill = list(Proportion = 0)) |>
  gt() |>
  tab_header(
    title = "Percentage of Simulations that had Correct Matches of Baby to Parents",
    subtitle = "10,000 Simulations of 4 Babies") |>
  fmt_percent(
    columns = everything(),
    decimals = 2)


result_table

```

**Revision: To showcase the use of joins I revised a few parts of my original code. I ran the simulations with 4 babies. I stored that inside of results_df. I used an anti_join to check if any of the scenarios would be missing from the results, and to ensure that even if some proportions were equivalent to 0 they were still shown in the table. I used bind_rows to put the missing scenarios inside the results data frame. After creating the labels I wanted in the table, I used a left_join to merge these labels with the results. The rest of the code was from my original code for this question in Lab 9, with the additional reference of** <https://sparkbyexamples.com/r-programming/r-anti-join/>.

**WD-7: I can pivot data frames from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

From Challenge 9 Question 3 from Lab 3:
  
evals |>
  distinct(teacher_id, .keep_all = TRUE) |>
  mutate(
    seniority = as.numeric(seniority),
    sen_level = ifelse(seniority <= 4,
                       "Junior (4 years or less)",
                       "Senior (more than 4 years)")) |>
  pivot_longer(cols = c(sex, 
                        sen_level, 
                        academic_degree),
               names_to = "demographic",
               values_to = "category") |>
  count(category) |>
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = list(n = 0)) |>
  select(Female = female,
         Male = male,
         "Junior (4 years or less)",
         "Senior (more than 4 years)",
         `No Degree` = no_dgr,
         Masters = ma,
         Doctorate = dr,
         Professor = prof) |>
  kable(format = "html", 
        caption = "Demographic Summary of Teachers from Evals Dataset") |>
  kable_styling()
  

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide

From Challenge 9 Question 3 from Lab 3:
  
evals |>
  distinct(teacher_id, .keep_all = TRUE) |>
  mutate(
    seniority = as.numeric(seniority),
    sen_level = ifelse(seniority <= 4,
                       "Junior (4 years or less)",
                       "Senior (more than 4 years)")) |>
  pivot_longer(cols = c(sex, 
                        sen_level, 
                        academic_degree),
               names_to = "demographic",
               values_to = "category") |>
  count(category) |>
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = list(n = 0)) |>
  select(Female = female,
         Male = male,
         "Junior (4 years or less)",
         "Senior (more than 4 years)",
         `No Degree` = no_dgr,
         Masters = ma,
         Doctorate = dr,
         Professor = prof) |>
  kable(format = "html", 
        caption = "Demographic Summary of Teachers from Evals Dataset") |>
  kable_styling()
  
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments: Lab 7, Lab 8, Lab 9, Challenge 9

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

From Lab 9 Question 8:

#Create plot of simulation means
ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, 
                 fill = "gray", 
                 color = "black", 
                 alpha = .7) +
#Facet by n(number of simulations) to show the different sample sizes clearly
  facet_wrap(~n, 
             scales = "free", 
             labeller = labeller(n = c("10" = "Simulations of 10", 
                              "100" = "Simulations of 100", 
                              "1000" = "Simulations of 1000", 
                              "10000" = "Simulations of 10000"))) +
#Add vertical line to show on plot where mean lies
  geom_vline(xintercept = 10, 
             color = "orange", 
             linetype = "solid", 
             size = 1) +
#Add labels to the plot
  labs(
    title = "Distribution of Simulated Means from each of the Simulations",
    x = "Simulated Mean",
    y = "") +
#Change theme from standard for better readability 
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, 
                              face = "bold"),
    axis.text = element_text(size = 11))
```

**Revision: I added code comments to help the reader understand what each step is doing and why.**

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2

From Lab 3 Question 5:
  
  teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  select(course_id,
         teacher_id,
         question_no,
         no_participants,
         resp_share,
         SET_score_avg,
         percent_failed_cur,
         academic_degree,
         seniority,
         sex) |>
  mutate(teacher_id = as.character(teacher_id),
         course_id = as.character(course_id)) |>
  filter(no_participants >= 10)
```

-   Example of function formatting

```{r}
#| label: r-2-3

From Challenge 7 Question 3:

calc_condition_index_df <- function(df, weight_col, length_col) {
  # Input checks
  stopifnot(
    "Input for df must be a data frame" = is.data.frame(df),
    "Weight column must exist in the data frame" = weight_col %in% colnames(df),
    "Length column must exist in the data frame" = length_col %in% colnames(df))
  
  # Calculate the condition index
  df <- df |> 
    mutate(
      condition_index = ({{weight_col}} / ({{length_col}}^3)) * 100)
  
  return(df)
}
  
```

**Revision: Because my function needs to operate on data frames, I changed () to be {}. I also added code comments to help explain what each step is doing. I also included an additional input check to make sure the function only operates on data frames.**

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context

```{r}
#| label: r-3-example

From Challenge 7 Question 3:

calc_condition_index_df <- function(df, weight_col, length_col) {
  # Input checks
  stopifnot(
    "Input for df must be a data frame" = is.data.frame(df),
    "Weight column must exist in the data frame" = weight_col %in% colnames(df),
    "Length column must exist in the data frame" = length_col %in% colnames(df))
  
  # Calculate the condition index
  df <- df |> 
    mutate(
      condition_index = ({{weight_col}} / ({{length_col}}^3)) * 100)
  
  return(df)
}
```

**Revision: Because my function needs to operate on data frames, I changed () to be {}. I also added code comments to help explain what each step is doing. I also included an additional input check to make sure the function only operates on data frames.**

-   Example of function stops

```{r}
#| label: r-3-function-stops

From Lab 7 Question 4:
  
rescale_01 <- function(x) {
  stopifnot("input has to be numeric" = is.numeric(x),
            "input has to have more than one element" = length(x) >1)
  range_x <- range(x, na.rm = TRUE)
  max_x <- range_x[2]
  min_x <- range_x[1]
  
  rescaled_x <- (x-min_x) / (max_x - min_x)
  
  return(rescaled_x)
} 
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables

```{r}
#| label: dvs-1-num

From Lab 2 Question 8:
  
ggplot(data = surveys,
       mapping = aes( x = weight, y = hindfoot_length)) +
         geom_point(alpha = .5) +
         facet_wrap(~species) +
  labs(title = "Weight vs. Hindfoot Length by Species",
       y = "",
       subtitle = " Hindfoot Length")
```

-   at least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat

From Lab 9 Question 8:
  
ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, 
                 fill = "gray", 
                 color = "black", 
                 alpha = .7) +
  facet_wrap(~n, 
             scales = "free", 
             labeller = labeller(n = c("10" = "Simulations of 10", 
                              "100" = "Simulations of 100", 
                              "1000" = "Simulations of 1000", 
                              "10000" = "Simulations of 10000"))) +
  geom_vline(xintercept = 10, 
             color = "orange", 
             linetype = "solid", 
             size = 1) +
  labs(
    title = "Distribution of Simulated Means from each of the Simulations",
    x = "Simulated Mean",
    y = "") +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, 
                              face = "bold"),
    axis.text = element_text(size = 11))
```

**Revision: I changed the word "Simulation" to "Simulations" in my labels to show that there were multiple simulations that occurred.**

-   at least two categorical variables

```{r}
#| label: dvs-2-cat

From Challenge 3 Question 2:
  
ggplot(teacher_evals_compare, aes(x = sen_level, fill = SET_level)) +
  geom_bar(stat = "count", 
           position = "stack") +
  labs(title = "Number of Sections",
    x = "Seniority of Instructor",
    y = "") +
    theme_minimal(base_size = 14)
  
```

-   dates (timeseries plot)

```{r}
#| label: dvs-2-date

From Challenge 7 Question 4:

fish_with_condition <- calc_condition_index_df(fish, weight_col = "weight", length_col = "length")

fish_condition_summary <- fish_with_condition |>
  group_by(year, section, species) |>
  summarise(average_condition_index = mean(condition_index, na.rm = TRUE), .groups = "drop")

ggplot(fish_condition_summary, aes(x = year, y = average_condition_index, color = section)) +
  geom_line(aes(group = section), linewidth = 1.5) +  
  geom_point(size = 3) +  
  labs(
    title = "Variation in Fish Condition Index Over Time",
    subtitle = "Average fish condition index by year, section, and species of fish",
    x = "Year",
    y = "",
    color = "Section") +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 0, hjust = 1),  
    axis.text.y = element_text(size = 10),
    legend.position = "bottom",  
    legend.title = element_text(size = 10),) +
  facet_wrap(~species, scales = "free_y") 

```

**Revision: I updated the code to use the function I had made prior. I adjusted my angle of rotation so that people do not have to tilt their heads to read the graph labels. I moved my legend to be underneath the graph making it more visually appealing and easier to navigate. I included a facet_wrap() to show how conditions have varied by species of fish.**

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head

```{r}
#| label: dvs-2-1

From Lab 9 Question 8:

ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, 
                 fill = "gray", 
                 color = "black", 
                 alpha = .7) +
  facet_wrap(~n, 
             scales = "free", 
             labeller = labeller(n = c("10" = "Simulations of 10", 
                              "100" = "Simulations of 100", 
                              "1000" = "Simulations of 1000", 
                              "10000" = "Simulations of 10000"))) +
  geom_vline(xintercept = 10, 
             color = "orange", 
             linetype = "solid", 
             size = 1) +
  labs(
    title = "Distribution of Simulated Means from each of the Simulations",
    x = "Simulated Mean",
    y = "") +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, 
                              face = "bold"),
    axis.text = element_text(size = 11)


```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-2

From Challenge 2 Level Hot:
  
labelsdf <- surveys |>
  group_by(species) |>
  summarize(max = max(weight)) |>
  mutate(xloc = max + 45, 
         label = c( "Neomota", 
                    "Chaetodipus",
                    "Peromyscus",
                    "Perognathus",
                    "Reithrodontomys",
                    "Sigmodon",
                    "Onychomys",
                    "Peromyscus",
                    "Reithrodontomys",
                    "Dipodomys",
                    "Dipodomys",
                    "Chaetodipus",
                    "Dipodomys",
                    "Onychromys"))

ggplot(data = surveys, mapping = aes(y = species, x = weight)) +
  geom_boxplot(aes(color = genus,
                   outliers = FALSE)) +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Weight (g) vs. Species (mm)",
       subtitle = "Distribution by Species",
       y = "") +
  geom_text(data = labelsdf, 
            mapping = aes(x = xloc,
                      y = species,
                      label = label)) +
  theme(axis.text.y = element_text(angle = 0, hjust = 1),
        legend.position = "none") +
  xlim(0, 350) 

```

**Revision: I revised the code from Lab 2 that got used in Challenge 2 to correct the printing errors and by making sure + was included after each element. I then added annotations by creating a separate data frame that had the genus types and the locations on the graph where I wanted them, and then using geom_text function to display the genus of the species on the graph in line with each box plot. I also decided to change the color scheme to be a little more creative and also more visually appealing.**

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-3

From Lab 7 Question 2:
  
fish_data |>   
  filter(is.na(weight)) |> 
  group_by(year, section, trip) |> 
  summarise(missing = n()) |> 
  ggplot(mapping = aes(x = missing, 
                       y = interaction(year, trip), 
                       fill = section)) + 
  geom_bar(stat = "identity", 
           position = "stack") + 
  scale_fill_manual(values = c("gray80", "darkred")) + 
  labs(title = "Frequency of Missing Weight Values by Year and Trip",
       subtitle = "Year and trip number",
       x = "Count of Missing Values of Weight",
       y = "",
       fill = "Section") + 
  theme_minimal() + 
  theme(
    aspect.ratio = 1/2, 
    axis.text.y = element_text(size = 8, angle = 0, hjust = 1), 
    legend.title = element_text(size = 10),
    legend.position = "bottom", 
    legend.direction = "horizontal")
```

**Revision: I adjusted the angle of the y axis text to be 0 so that there is no tilt and the reader can easily read without tilting their head at all.**

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors

```{r}
#| label: dvs-3-1

From Challenge 2 Level Hot:
  
labelsdf <- surveys |>
  group_by(species) |>
  summarize(max = max(weight)) |>
  mutate(xloc = max + 45, 
         label = c( "Neomota", 
                    "Chaetodipus",
                    "Peromyscus",
                    "Perognathus",
                    "Reithrodontomys",
                    "Sigmodon",
                    "Onychomys",
                    "Peromyscus",
                    "Reithrodontomys",
                    "Dipodomys",
                    "Dipodomys",
                    "Chaetodipus",
                    "Dipodomys",
                    "Onychromys"))

ggplot(data = surveys, mapping = aes(y = species, x = weight)) +
  geom_boxplot(aes(color = genus,
                   outliers = FALSE)) +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Weight (g) vs. Species (mm)",
       subtitle = "Distribution by Species",
       y = "") +
  geom_text(data = labelsdf, 
            mapping = aes(x = xloc,
                      y = species,
                      label = label)) +
  theme(axis.text.y = element_text(angle = 0, hjust = 1),
        legend.position = "none") +
  xlim(0, 350) 

```

**Revision: I revised the code from Lab 2 that got used in Challenge 2 to correct the printing errors and by making sure + was included after each element. I then added annotations by creating a separate data frame that had the genus types and the locations on the graph where I wanted them, and then using geom_text function to display the genus of the species on the graph in line with each box plot. I also decided to change the color scheme to be a little more creative and also more visually appealing.**

-   I can use annotations

```{r}
#| label: dvs-3-2

From Challenge 2, Level Hot:

labelsdf <- surveys |>
  group_by(species) |>
  summarize(max = max(weight)) |>
  mutate(xloc = max + 45, 
         label = c( "Neomota", 
                    "Chaetodipus",
                    "Peromyscus",
                    "Perognathus",
                    "Reithrodontomys",
                    "Sigmodon",
                    "Onychomys",
                    "Peromyscus",
                    "Reithrodontomys",
                    "Dipodomys",
                    "Dipodomys",
                    "Chaetodipus",
                    "Dipodomys",
                    "Onychromys"))

ggplot(data = surveys, mapping = aes(y = species, x = weight)) +
  geom_boxplot(aes(color = genus,
                   outliers = FALSE)) +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Weight (g) vs. Species (mm)",
       subtitle = "Distribution by Species",
       y = "") +
  geom_text(data = labelsdf, 
            mapping = aes(x = xloc,
                      y = species,
                      label = label)) +
  theme(axis.text.y = element_text(angle = 0, hjust = 1),
        legend.position = "none") +
  xlim(0, 350) 

```

**Revision: I revised the code from Lab 2 that got used in Challenge 2 to correct the printing errors and by making sure + was included after each element. I then added annotations by creating a separate data frame that had the genus types and the locations on the graph where I wanted them, and then using geom_text function to display the genus of the species on the graph in line with each box plot. I also decided to change the color scheme to be a little more creative and also more visually appealing.**

-   I can be creative...

```{r}
#| label: dvs-3-3


From Lab 9 Question 8:

ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, 
                 fill = "gray", 
                 color = "black", 
                 alpha = .7) +
  facet_wrap(~n, 
             scales = "free", 
             labeller = labeller(n = c("10" = "Simulation of 10", 
                              "100" = "Simulation of 100", 
                              "1000" = "Simulation of 1000", 
                              "10000" = "Simulation of 10000"))) +
  geom_vline(xintercept = 10, 
             color = "orange", 
             linetype = "solid", 
             size = 1) +
  labs(
    title = "Distribution of Simulated Means from each of the Simulations",
    x = "Simulated Mean",
    y = "") +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, 
                              face = "bold"),
    axis.text = element_text(size = 11)

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

From Lab 3 Question 10:

average_ratings <- teacher_evals_clean |>
  group_by(teacher_id) |>
  filter(question_no == 901) |>
    summarize(
      avg_q1_score = mean(SET_score_avg), .groups = 'drop') |>
    filter(avg_q1_score == min(avg_q1_score) |
           avg_q1_score == max(avg_q1_score))


print(average_ratings) 
```

-   Example using `across()`

```{r}
#| label: dvs-4-across

From Lab 7 Question 1:
  
 fish_data |>
  summarise(across(.fns = ~sum(is.na(.)), .names = "missing_{.col}")) |>
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "missing_count") 
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

From Lab 7 Question 2:
  
fish_data |> 
  filter(is.na(weight)) |> 
  group_by(year, section, trip) |> 
  summarise(missing = n()) |> 
  ggplot(mapping = aes(x = missing, 
                       y = interaction(year, trip), 
                       fill = section)) + 
  geom_bar(stat = "identity", 
           position = "stack") + 
  scale_fill_manual(values = c("gray80", "darkred")) + 
  labs(title = "Frequency of Missing Weight Values by Year and Trip",
       subtitle = "Year and trip number",
       x = "Count of Missing Values of Weight",
       y = "",
       fill = "Section") + 
  theme_minimal() + 
  theme(
    aspect.ratio = 1/2, 
    axis.text.y = element_text(size = 8, angle = 0, hjust = 1), 
    legend.title = element_text(size = 10),
    legend.position = "bottom", 
    legend.direction = "horizontal")
```

**Revision: I adjusted the angle of the y axis text to be 0 so that there is no tilt and the reader can easily read without tilting their head at all.**

-   Example 2

```{r}
#| label: dvs-5-2

From Lab 3 Question 9:
  
teacher_evals_clean |>
  group_by(course_id, teacher_id) |>
  summarize(question_count = n_distinct(question_no), .groups = 'drop') |>
  filter(question_count == 9)
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r}
#| label: dvs-6-1

From Lab 9 Question 2:
  
library(gt)
results_updated <- map_int(1:10000, ~randomBabies(4))

result_table <- enframe(results_updated, name = "simulation number", value = "ncorrect") |>
  count(ncorrect) |>
  complete(ncorrect = 0:4, fill = list(n = 0)) |>
  mutate(Proportion = n / 10000) |>
  select(-n) |>
  pivot_wider(names_from = ncorrect, values_from = Proportion, values_fill = list(Proportion = 0)) |>
  rename(
    `0 Correct Matches` = `0`,
    `1 Correct Match` = `1`,
    `3 Correct Matches` = `3`,
    `2 Correct Matches` = `2`,
    `4 Correct Matches` = `4`) |>
  gt() |>
  tab_header(
    title = "Percentage of Simulations that had Correct Matches of Baby to Parents",
    subtitle = "10,000 Simulations of 4 Babies") |>
  fmt_percent(
    columns = everything(),
    decimals = 2) 
  
  

result_table
```

-   Example 2

```{r}
#| label: dvs-6-2

From Challenge 9 Question 4 from Lab 7:
  
missing_values <- 
  tibble(
  variable = names(fish),
  `Number Missing` = map_int(fish, ~sum(is.na(.)))) |>
  kable(
    format = "html",
    caption = "Number of Missing Values for Each Variable in Fish Data")

missing_values


```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r}
#| label: dvs-7-1

From Lab 9 Question 2:
  
library(gt)
results_updated <- map_int(1:10000, ~randomBabies(4))

result_table <- enframe(results_updated, name = "simulation number", value = "ncorrect") |>
  count(ncorrect) |>
  complete(ncorrect = 0:4, fill = list(n = 0)) |>
  mutate(Proportion = n / 10000) |>
  select(-n) |>
  pivot_wider(names_from = ncorrect, values_from = Proportion, values_fill = list(Proportion = 0)) |>
  rename(
    `0 Correct Matches` = `0`,
    `1 Correct Match` = `1`,
    `3 Correct Matches` = `3`,
    `2 Correct Matches` = `2`,
    `4 Correct Matches` = `4`) |>
  gt() |>
  tab_header(
    title = "Percentage of Simulations that had Correct Matches of Baby to Parents",
    subtitle = "10,000 Simulations of 4 Babies") |>
  fmt_percent(
    columns = everything(),
    decimals = 2) 
  
  

result_table

```

-   Example 2

```{r}
#| label: dvs-7-2

From Lab 9 Question 7:
  
table_of_means_spicy <- all_simulations |>
  group_by(n, df) |>
  summarize(
    "Max of Simulation Means" = max(simulated_means),
    "Mean of the Simulation" = mean(simulated_means),
    "Min of Simulation Means" = min(simulated_means),
    .groups = 'drop' ) |>
  rename(
    "# of Simulations" = n) |>
  kable(
    format = "html",
    caption = "Table of Means from Each of the Simulations")
  
table_of_means_spicy


```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

From Lab 7 Question 9:
  
fish_data_rescaled <- rescale_column(fish_data, c(length, weight))

```

-   `across()`

```{r}
#| label: pe-1-across

From Lab 7 Question 8:
  
rescale_column <- function(df, vars) {
  df_rescaled <- df |>
    mutate(
      across({{vars}}, ~ rescale_01(.x))  
    )
  return(df_rescaled)
}
```

-   `map()` functions

```{r}
#| label: pe-1-map-1

From Challenge 9 Question 4 From Lab 7:
  
missing_values <- 
  tibble(
  variable = names(fish),
  `Number Missing` = map_int(fish, ~sum(is.na(.)))) |>
  kable(
    format = "html",
    caption = "Number of Missing Values for Each Variable in Fish Data")

missing_values
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors

```{r}
#| label: pe-2-1

From Lab 9 Question 1:
  
randomBabies <- function(nBabies){
  
  random_baby_data <- sample(1:nBabies, nBabies, replace = FALSE)
  
  return(sum(random_baby_data ==1:nBabies))
}

```

-   Function that operates on data frames

```{r}
#| label: pe-2-2

From Challenge 7 Question 3:

calc_condition_index_df <- function(df, weight_col, length_col) {
  # Input checks
  stopifnot(
    "Input for df must be a data frame" = is.data.frame(df),
    "Weight column must exist in the data frame" = weight_col %in% colnames(df),
    "Length column must exist in the data frame" = length_col %in% colnames(df))
  
  # Calculate the condition index
  df <- df |> 
    mutate(
      condition_index = ({{weight_col}} / ({{length_col}}^3)) * 100)
  
  return(df)
}
```

**Revision: Because my function needs to operate on data frames, I changed () to be {}. I also added code comments to help explain what each step is doing. I also included an additional input check to make sure the function only operates on data frames.**

**PE-3: I can use iteration to reduce repetition in my code.**

-   `across()`

```{r}
#| label: pe-3-across

From Lab 7 Question 8:
  
rescale_column <- function(df, vars) {
  df_rescaled <- df |>
    mutate(
      across({{vars}}, ~ rescale_01(.x))  
    )
  return(df_rescaled)
}
```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

From Challenge 9, Question 1 from Lab 2:
  
table_of_data1 <- 
  tibble(
  Variable = names(surveys),
  `Data Type` = map_chr(surveys, ~ class(.x))) |>
  pivot_wider(
    names_from = Variable,
    values_from = `Data Type`) |>
  kable(
    format = "html",
    caption = "Data Types of Variables in the Surveys Dataset")


table_of_data1
```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{r}
#| label: pe-3-map-2

From Lab 9 Question 6:

all_simulations <- grid |> 
  mutate(
    simulated_means = pmap(
      .l = list(n = n, df = df), 
      .f = ~ simulate_means(n = .x, df = .y))) |> 
  unnest(cols = simulated_means) 
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

From Lab 3 Question 7:
  
missing_values_data <- teacher_evals_clean |>
  filter(if_any(everything(), is.na))
```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

From Lab 7 Question 2:
  
fish_data |>   
  filter(is.na(weight)) |> 
  group_by(year, section, trip) |> 
  summarise(missing = n()) |> 
  ggplot(mapping = aes(x = missing, 
                       y = interaction(year, trip), 
                       fill = section)) + 
  geom_bar(stat = "identity", 
           position = "stack") + 
  scale_fill_manual(values = c("gray80", "darkred")) + 
  labs(title = "Frequency of Missing Weight Values by Year and Trip",
       subtitle = "Year and trip number",
       x = "Count of Missing Values of Weight",
       y = "",
       fill = "Section") + 
  theme_minimal() + 
  theme(
    aspect.ratio = 1/2, 
    axis.text.y = element_text(size = 8, angle = 0, hjust = 1), 
    legend.title = element_text(size = 10),
    legend.position = "bottom", 
    legend.direction = "horizontal")

```

**Revision: I adjusted the angle of the y axis text to be 0 so that there is no tilt and the reader can easily read without tilting their head at all.**

## Data Simulation & Statistical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1

From Lab 9 Question 1:
  
randomBabies <- function(nBabies){
  
  random_baby_data <- sample(1:nBabies, nBabies, replace = FALSE)
  
  return(sum(random_baby_data ==1:nBabies))
  
} 

results <- map_int(1:10000, ~randomBabies(4))
```

**Revision: I removed my saved table which included a nested function and instead just ran the simulation and stored it inside of "results."**

-   Example 2

```{r}
#| label: dsm-1-2

From Lab 9 Question 4:
  
simulate_means <- function(n, df){
  map_dbl(.x = 1:n, 
          .f = ~rchisq(n = 100, df = df) %>% mean())
}
```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

From Lab 2 Question 17:
  
species_mod <- aov(weight ~ species, data = surveys)

summary(species_mod)
```

-   Example 2

```{r}
#| label: dsm-2-2

From Challenge 3 Question 3

chi_square_result <- chisq.test(teacher_evals_compare$SET_level,
                                teacher_evals_compare$sen_level)

```

**Revision: Based on the feedback given on the Challenge, I removed the unnecessary object of the contingency table, and directly plugged my data into the chisq.test function. Based on Midterm feedback, I removed the table portion of the function because I do not need to create a contingency table.**

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

I revised my thinking by being open minded. I am not always going to "get it" the first try and I know that about myself. I take all the feedback I get and go compare it to my original code and what I was thinking at the time of writing it. I try to see why the feedback was given but also why it is better than my own. My own code may get the job done, but I revise my thinking to be as proficient as I can have my code be. I revised my thinking on some of the examples in this portfolio by doing exactly this. I revised many of my graphs to have unique colors and detailed titles/labels, and to be more creative. Small things like this make my output more concise and efficient, even though my code before ran and worked to produce a basic plot/table.

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

Similarly to how I revised my thinking, I try to be open minded and be open to new ways to make my code better. I extended my thinking by doing what I listed above in the Revised thinking section, and by also doing my own extended research. If I notice things are not making sense, and I have already reviewed the slides, I will try to extend my thinking by reviewing the feedback given on Labs, asking my peers, researching the topics talked about in class and in lecture slides, and find new ways to use the functions we talk about. I extended my thinking in the revisions in my portfolio by implementing more efficient ways to do the same thing as I had. For example fixing the chi square test to run off of just the data file rather than creating a contingency table first. I also extended my thinking in my graphs by trying to put as much detail into them without overpowering them and making them look cluttered. My idea behind this was trying to put myself in the shoes of someone who has no idea what the labs are about, but are able to understand what my graph is about with some amount of context.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

![](images/Screenshot%202024-11-03%20at%206.09.23%20PM.png){width="359"}

If that image didn't show up, here is what I wrote as peer feedback:

Hi Amir, I noticed that you formatted your code really well, making sure to indent when needed and not putting everything on one line. I thought your use of the pipe operator was efficiently used as well. A suggestion I have for you would be to add section headers to make your steps easier to follow. This would also help to organize your document and make it more reader friendly and tidy. Overall good job!

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

I grew as a collaborator with the weekly pair activities by really trying hard to stick with the roles given throughout the assignment. I found this to be difficult at first; waiting my turn to give ideas when my job was to type. Something I learned from this and really try to utilize in my day to day life is that communicating should be more about listening and hearing the other person and what they have to say, rather than just waiting for my turn to speak. I really feel my level of patience has improved by practicing collaborating this way.
